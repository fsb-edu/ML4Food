{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview of Machine Learning for Food Sciences"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Overview**\n",
    "\n",
    "In this tutorial you will learn:\n",
    "- What is Machine Learning?\n",
    "- Applications of Machine Learning in Food Science\n",
    "- Datasets we will use throughout the tutorials\n",
    "- Data pre-processing steps\n",
    "- Train-test split\n",
    "- Standardization"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to Machine Learning"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probably you should have heard a lot about \"Machine Learning\" so far, and fairly you might have asked yourself: What does it mean? Machine Learning lies in the intersection between computer science and statistics/mathematics. The first to coin a definition for machine learning was Arthur Samuel in 1959. According to Samuel, ***\"machine learning is the field of study  that gives computers the ability to learn without being explicitly programmed\"***.\n",
    "\n",
    "**The main goal of Machine Learning is to extract \"meaning\" from data**. This \"meaning\" is in practice represented as a **mathematical equation that best describes the data**. In a philosophical perspective, Machine Learning is used to get knowledge from data. By using this extracted knowledge it is possible to make useful predictions.\n",
    "\n",
    "Although sometimes it might not be evident, machine learning algorithms are vastly part of our lives. Some simple examples in your everyday lives would be the face-detection features in our smartphones, the voice assistants in our electronic devices, spam filters in our emails, etc. Other areas were the usage of machine learning is gathering momentum is medicine: machine learning algorithms can detect diseases with high accuracy, they can also be used to predict efficiency of different drug combinations which normally is an extremely time-consuming process."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Figure 1](#ml-model) shows a high level view of the process of building a machine learning model. Everything begins by pre-processing the raw data. After we polish it and make it usable by the machine learning models, we split the **processed data** into two parts: **the training data** and **the testing data**. The **training data** is fed into the model so that it can learn a good mathematical representation of it. The **process of building the model** consist of several  steps. When we build the model, we do not give it all the data that we have. The reasons for the split will become evident in [the train-test split section below](#train-test-split). Then we choose a specific machine learning model. **The model is trained on the training data**. After the model training si done, we can use it to predict some results on the test data, outputing the **predicted outputs**. Given model predictions, we can check how the model has performed. This happens because we iteratively train the model, check how it performs on unseen data and then, if the results are not good we go back to training and repeat the process until we reach some satisfactory results. When it reaches an optimal performance we assume the model is ready to be used in real world scenarios.\n",
    "How do we determine whether a model is performing well or how do we measure the performance it depends on the task at hand. We will see some examples later on.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<a id=\"ml-model\"></a>\n",
    "<img src=\"images/part1_overview/ml_pipeline.jpg\" alt=\"Machine Learning Model\" width=\"75%\">\n",
    "<center><figcaption><em>Fig 1: Building a machine learning model</em></figcaption></center>\n",
    "</center>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generally, there are 4 types of machine learning algorithms: *supervised learning*, *unsupervised learning*, *semi-supervised learning* and *reinforcement learning*. In this series of tutorials we will explore supervised and unsupervised learning algorithms.\n",
    "\n",
    "**Supervised Learning** - in this setting we aim to build a model that will learn the data the best and will be able to predict future values. The data points that the model uses to learn, already have the corresponding outputs. This is how the model is able to derive a connection between inputs and outputs. There are two types of problems in the supervised setting: *regression* and *classification*. In **regression**, the output that the model learns and then tries to predict is a continuous value. In **classification**, the output that the model learns and then tries to predict is a categorical value. \n",
    "\n",
    "**Unsupervised Learning** - in this setting, the data that we have does not have any values or categories that we can learn and later predict. Here, the models will try to find a structure in the data, or learn patterns present. Some use cases of such models would be: **clustering**, **dimensionality reduction**, data generation, anomaly detection etc. In the case of **clustering**, we try to find groups within the data, so that we can group similar samples together. In the case of **dimensionality reduction**, we move from data with many features, to compressed data, with very few features. \n",
    "\n",
    "We will study these types in detail in the following tutorials."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To conclude this section, let us emphasize again the \"power\" of Machine Learning. By using Machine Learning algorithms, we can (refer to the lighbulbs in [Figure 1](#ml-model)):\n",
    "1. learn patterns/relationships in our data that might not be clearly evident \n",
    "2. perform predictions on new data "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Where Machine Learning is Used in Food Science?[to be discussed with field experts....]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Text removed from here. Initial text can be found in `for_ml_applications_in_food_science.txt`]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets Used during the Tutorials"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[To be completed in the very end...]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing for Machine Learning Methods"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since ML models are built from data, the performance of the trained models depends on the quality of the data fed into the model. So, to build robust machine learning algorithms, data quality is very important. In most of the cases the data that we get is raw. If we use it as it is, the model may not be able to learn many useful characteristics. Thus, we need to pre-process the data by applying different techniques, so that it can be useful to the model. Below we brief some of these techniques.\n",
    "\n",
    "The preprocessing steps that we will apply to make the data usable will be:\n",
    "1. Data Quality Control\n",
    "2. Train-Test split\n",
    "3. Standardization\n",
    "\n",
    "In the following sections we will explore how each of the above mentioned steps is performed and how we end up with data that is ready to be used in a machine learning model. But first, let us explore our original dataset."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Anatomy of our data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By **data** we refer to the **collection of samples** obtained through different experimental procedures. Usually, machine learning models work with data in tabular format. In machine learning notation, we denote **the number of samples by m** and **the number of features by n**. By the number of samples we mean the number fo data points. While features determine the characteristics of each of these data points. The machine learning models use these features to learn insights and to construct a mathematical equation that will represent the data.\n",
    "\n",
    "Let us illustrate this with our dataset."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing to do is to import the Python modules that we will need for reading the data and then for processing. \n",
    "What you see below are some of the most important modules. We will use the `train_test_split` function of the `sklearn.model_selection` module later to do the train-test split. We will use the `pandas` library to read and interact with the data. `math` is another library that we will use throughout our pre-processing steps. This provides different mathematical functions. The `StandardScaler` object will be needed for the standardization step, while `matplotlib` and `seaborn` will be used for visualizations. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import math\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the above cell finishes running successfully, you will see `[1]`, in the bottom left corner of the box. This means that the packages are loaded and ready to be used. After this, we are ready to read the data."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the `read_csv` function of the `pandas` library to read the dataset. The dataset is in a `.csv` (comma separated values) file and we will save it in a **pandas dataframe**. Note that here we use the alias of the `pandas` library `pd`. We deined it in the above code cell with the `as` clause. \n",
    "\n",
    "After reading the dataset, we use the `head()` method of the `dataset` dataframe to see the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>name</th>\n",
       "      <th>category</th>\n",
       "      <th>energy_kcal</th>\n",
       "      <th>fat_g</th>\n",
       "      <th>fatty_acids_sat_g</th>\n",
       "      <th>fatty_acids_monounsat_g</th>\n",
       "      <th>fatty_acids_polyunsat_g</th>\n",
       "      <th>cholesterol_mg</th>\n",
       "      <th>carbohydrates_g</th>\n",
       "      <th>...</th>\n",
       "      <th>potassium_mg</th>\n",
       "      <th>sodium_mg</th>\n",
       "      <th>chloride_mg</th>\n",
       "      <th>calcium_mg</th>\n",
       "      <th>magnesium_mg</th>\n",
       "      <th>phosphorus_mg</th>\n",
       "      <th>iron_mg</th>\n",
       "      <th>iodide_µg</th>\n",
       "      <th>zinc_mg</th>\n",
       "      <th>selenium_µg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Agar Agar</td>\n",
       "      <td>other</td>\n",
       "      <td>160.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>52.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>660.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Agave syrup</td>\n",
       "      <td>sweets</td>\n",
       "      <td>293.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>73.1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Almond</td>\n",
       "      <td>fruits</td>\n",
       "      <td>624.0</td>\n",
       "      <td>52.1</td>\n",
       "      <td>4.1</td>\n",
       "      <td>31.4</td>\n",
       "      <td>11.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.8</td>\n",
       "      <td>...</td>\n",
       "      <td>740.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>40.0</td>\n",
       "      <td>270.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>510.0</td>\n",
       "      <td>3.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3.3</td>\n",
       "      <td>2.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Almond, dry roasted, salted</td>\n",
       "      <td>nuts</td>\n",
       "      <td>637.0</td>\n",
       "      <td>52.5</td>\n",
       "      <td>4.1</td>\n",
       "      <td>33.1</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.1</td>\n",
       "      <td>...</td>\n",
       "      <td>710.0</td>\n",
       "      <td>230.0</td>\n",
       "      <td>1190.0</td>\n",
       "      <td>270.0</td>\n",
       "      <td>280.0</td>\n",
       "      <td>470.0</td>\n",
       "      <td>3.7</td>\n",
       "      <td>2.4</td>\n",
       "      <td>3.3</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Almond, roasted, salted</td>\n",
       "      <td>nuts</td>\n",
       "      <td>649.0</td>\n",
       "      <td>55.2</td>\n",
       "      <td>4.2</td>\n",
       "      <td>34.8</td>\n",
       "      <td>13.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.2</td>\n",
       "      <td>...</td>\n",
       "      <td>670.0</td>\n",
       "      <td>330.0</td>\n",
       "      <td>1190.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>270.0</td>\n",
       "      <td>470.0</td>\n",
       "      <td>3.3</td>\n",
       "      <td>2.4</td>\n",
       "      <td>3.1</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID                         name category  energy_kcal  fat_g  \\\n",
       "0   0                    Agar Agar    other        160.0    0.2   \n",
       "1   1                  Agave syrup   sweets        293.0    0.0   \n",
       "2   2                       Almond   fruits        624.0   52.1   \n",
       "3   3  Almond, dry roasted, salted     nuts        637.0   52.5   \n",
       "4   4      Almond, roasted, salted     nuts        649.0   55.2   \n",
       "\n",
       "   fatty_acids_sat_g  fatty_acids_monounsat_g  fatty_acids_polyunsat_g  \\\n",
       "0                NaN                      NaN                      NaN   \n",
       "1                0.0                      NaN                      NaN   \n",
       "2                4.1                     31.4                     11.4   \n",
       "3                4.1                     33.1                     13.0   \n",
       "4                4.2                     34.8                     13.5   \n",
       "\n",
       "   cholesterol_mg  carbohydrates_g  ...  potassium_mg  sodium_mg  chloride_mg  \\\n",
       "0             NaN              0.0  ...          52.0      130.0          NaN   \n",
       "1             NaN             73.1  ...           NaN        4.0          NaN   \n",
       "2             0.0              7.8  ...         740.0        1.1         40.0   \n",
       "3             0.0             10.1  ...         710.0      230.0       1190.0   \n",
       "4             0.0              7.2  ...         670.0      330.0       1190.0   \n",
       "\n",
       "   calcium_mg  magnesium_mg  phosphorus_mg  iron_mg  iodide_µg  zinc_mg  \\\n",
       "0       660.0         100.0           34.0      4.5        NaN      1.5   \n",
       "1         NaN           NaN            NaN      NaN        NaN      NaN   \n",
       "2       270.0         240.0          510.0      3.3        0.2      3.3   \n",
       "3       270.0         280.0          470.0      3.7        2.4      3.3   \n",
       "4       240.0         270.0          470.0      3.3        2.4      3.1   \n",
       "\n",
       "   selenium_µg  \n",
       "0          NaN  \n",
       "1          NaN  \n",
       "2          2.2  \n",
       "3          2.0  \n",
       "4          2.0  \n",
       "\n",
       "[5 rows x 42 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('data/swiss_food_composition_database_proc.csv')\n",
    "dataset.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each **row** is a called a **sample**. Each **column** represent a **feature**, or in other words a characteristic of a sample. In order to find how many samples and features we have, we can use the `shape` attribute of the `dataset` dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1092, 42)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from the ouput above, there are 1092 samples (rows) and 42 features (columns). `shape` returns a tuple with 2 values, the first one is the number of samples (rows) and the second one is the number of features (columns). As you can see, it shows 1092 rows and 42 columns."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Quality Control"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usually, the first step in the data pre-processing phase is to assess the quality of our data. There are different ways how to inspect this and here we will explore some of them."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find number of missing values"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us start by getting some information regarding what type of data the dataset contains. For this we will use the `info()` method of the `dataset` dataframe. Besides listing the data types of each column, it shows how many non-empy (`non-null`) values are there for each feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1092 entries, 0 to 1091\n",
      "Data columns (total 42 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   ID                         1092 non-null   int64  \n",
      " 1   name                       1092 non-null   object \n",
      " 2   category                   1092 non-null   object \n",
      " 3   energy_kcal                1092 non-null   float64\n",
      " 4   fat_g                      1092 non-null   float64\n",
      " 5   fatty_acids_sat_g          1087 non-null   float64\n",
      " 6   fatty_acids_monounsat_g    1085 non-null   float64\n",
      " 7   fatty_acids_polyunsat_g    1085 non-null   float64\n",
      " 8   cholesterol_mg             1080 non-null   float64\n",
      " 9   carbohydrates_g            1092 non-null   float64\n",
      " 10  sugars_g                   1087 non-null   float64\n",
      " 11  starch_g                   1038 non-null   float64\n",
      " 12  fibres_g                   1091 non-null   float64\n",
      " 13  protein_g                  1092 non-null   float64\n",
      " 14  salt_g                     1092 non-null   float64\n",
      " 15  alcohol_g                  1088 non-null   float64\n",
      " 16  water_g                    1090 non-null   float64\n",
      " 17  vit_A_activity_re_µg       1079 non-null   float64\n",
      " 18  vit_A_activity_rae_µg      1079 non-null   float64\n",
      " 19  retinol_µg                 1082 non-null   float64\n",
      " 20  beta_carotene_activity_µg  1073 non-null   float64\n",
      " 21  beta_carotene_µg           1071 non-null   float64\n",
      " 22  vit_B1_mg                  1085 non-null   float64\n",
      " 23  vit_B2_mg                  1086 non-null   float64\n",
      " 24  vit_B6_mg                  1085 non-null   float64\n",
      " 25  vit_B12_µg                 1082 non-null   float64\n",
      " 26  niacin_mg                  1052 non-null   float64\n",
      " 27  folate_µg                  1075 non-null   float64\n",
      " 28  panthotenic_acid_mg        1080 non-null   float64\n",
      " 29  vit_c_mg                   1079 non-null   float64\n",
      " 30  vit_d_µg                   1081 non-null   float64\n",
      " 31  vit_e_activity_mg          1085 non-null   float64\n",
      " 32  potassium_mg               1087 non-null   float64\n",
      " 33  sodium_mg                  1092 non-null   float64\n",
      " 34  chloride_mg                1068 non-null   float64\n",
      " 35  calcium_mg                 1087 non-null   float64\n",
      " 36  magnesium_mg               1085 non-null   float64\n",
      " 37  phosphorus_mg              1086 non-null   float64\n",
      " 38  iron_mg                    1087 non-null   float64\n",
      " 39  iodide_µg                  1071 non-null   float64\n",
      " 40  zinc_mg                    1086 non-null   float64\n",
      " 41  selenium_µg                360 non-null    float64\n",
      "dtypes: float64(39), int64(1), object(2)\n",
      "memory usage: 358.4+ KB\n"
     ]
    }
   ],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we see, most of the columns hold decimal values, which in Python corresponds to the **float64** data type.\n",
    "The first two columns, `Name` and `Category` are `strings` (sequences of characters) and `pandas` recognizes them as objects."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The missing values in the dataset are recorded as `NaN`s. Let us look at an example: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>name</th>\n",
       "      <th>category</th>\n",
       "      <th>energy_kcal</th>\n",
       "      <th>fat_g</th>\n",
       "      <th>fatty_acids_sat_g</th>\n",
       "      <th>fatty_acids_monounsat_g</th>\n",
       "      <th>fatty_acids_polyunsat_g</th>\n",
       "      <th>cholesterol_mg</th>\n",
       "      <th>carbohydrates_g</th>\n",
       "      <th>...</th>\n",
       "      <th>potassium_mg</th>\n",
       "      <th>sodium_mg</th>\n",
       "      <th>chloride_mg</th>\n",
       "      <th>calcium_mg</th>\n",
       "      <th>magnesium_mg</th>\n",
       "      <th>phosphorus_mg</th>\n",
       "      <th>iron_mg</th>\n",
       "      <th>iodide_µg</th>\n",
       "      <th>zinc_mg</th>\n",
       "      <th>selenium_µg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Agar Agar</td>\n",
       "      <td>other</td>\n",
       "      <td>160.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>52.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>660.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID       name category  energy_kcal  fat_g  fatty_acids_sat_g  \\\n",
       "0   0  Agar Agar    other        160.0    0.2                NaN   \n",
       "\n",
       "   fatty_acids_monounsat_g  fatty_acids_polyunsat_g  cholesterol_mg  \\\n",
       "0                      NaN                      NaN             NaN   \n",
       "\n",
       "   carbohydrates_g  ...  potassium_mg  sodium_mg  chloride_mg  calcium_mg  \\\n",
       "0              0.0  ...          52.0      130.0          NaN       660.0   \n",
       "\n",
       "   magnesium_mg  phosphorus_mg  iron_mg  iodide_µg  zinc_mg  selenium_µg  \n",
       "0         100.0           34.0      4.5        NaN      1.5          NaN  \n",
       "\n",
       "[1 rows x 42 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.iloc[0:1, :]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above example, we see that for `Agar Agar` we do not have a value for `fatty_acids_sat_g`, `fatty_acids_monounsat_g`, `fatty_acids_polyunsat_g`, etc."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing features with a lot of missing values"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The features (columns) that have a lot of missing values will not be useful for the models. That is why we need to remove them. Determining what *a lot* means depends on the context and task at hand. In our case, we will remove the features that have more than 20% of the values missing. For this we will need to find the actual minimum number of rows that have to contain a value per feature so that they will be kept. Since we will remove features that have more than 20% of the data missing, we will keep those that have at least 80%. We have 1092 samples in total, this means that we will keep features that have at least $$\\left\\lceil 0.8*1092=873.6\\right\\rceil = 874$$ non-missing values. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will print the number of `NaN` values per column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID                             0\n",
       "name                           0\n",
       "category                       0\n",
       "energy_kcal                    0\n",
       "fat_g                          0\n",
       "fatty_acids_sat_g              5\n",
       "fatty_acids_monounsat_g        7\n",
       "fatty_acids_polyunsat_g        7\n",
       "cholesterol_mg                12\n",
       "carbohydrates_g                0\n",
       "sugars_g                       5\n",
       "starch_g                      54\n",
       "fibres_g                       1\n",
       "protein_g                      0\n",
       "salt_g                         0\n",
       "alcohol_g                      4\n",
       "water_g                        2\n",
       "vit_A_activity_re_µg          13\n",
       "vit_A_activity_rae_µg         13\n",
       "retinol_µg                    10\n",
       "beta_carotene_activity_µg     19\n",
       "beta_carotene_µg              21\n",
       "vit_B1_mg                      7\n",
       "vit_B2_mg                      6\n",
       "vit_B6_mg                      7\n",
       "vit_B12_µg                    10\n",
       "niacin_mg                     40\n",
       "folate_µg                     17\n",
       "panthotenic_acid_mg           12\n",
       "vit_c_mg                      13\n",
       "vit_d_µg                      11\n",
       "vit_e_activity_mg              7\n",
       "potassium_mg                   5\n",
       "sodium_mg                      0\n",
       "chloride_mg                   24\n",
       "calcium_mg                     5\n",
       "magnesium_mg                   7\n",
       "phosphorus_mg                  6\n",
       "iron_mg                        5\n",
       "iodide_µg                     21\n",
       "zinc_mg                        6\n",
       "selenium_µg                  732\n",
       "dtype: int64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nan_total_col = dataset.isna().sum(axis=0)\n",
    "nan_total_col"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the list above, we will remove all columns that have more than 1092-874 = 218 missing values. Only the `selenium_µg` has more than 218 missing values."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above code cell does the following:\n",
    "\n",
    "It checks each value of the dataset and marks it with 1 if it is a `nan` and with a 0 otherwise. Then, it computes the sum of each column using the `sum()` method with the `axis=0`. In this way we find the number of 1s per column, which means the number of values that are `nan`s per column. You can find a visual explanation on [Figure 2](#boolean-mask-illustration) below."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can drop the columns that have more than 20% of the values missing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "874"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "percentage_present = 0.8\n",
    "feature_threshold = math.ceil(percentage_present*dataset.shape[0]) # 20% of values missing\n",
    "feature_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ID', 'name', 'category', 'energy_kcal', 'fat_g', 'fatty_acids_sat_g',\n",
       "       'fatty_acids_monounsat_g', 'fatty_acids_polyunsat_g', 'cholesterol_mg',\n",
       "       'carbohydrates_g', 'sugars_g', 'starch_g', 'fibres_g', 'protein_g',\n",
       "       'salt_g', 'alcohol_g', 'water_g', 'vit_A_activity_re_µg',\n",
       "       'vit_A_activity_rae_µg', 'retinol_µg', 'beta_carotene_activity_µg',\n",
       "       'beta_carotene_µg', 'vit_B1_mg', 'vit_B2_mg', 'vit_B6_mg', 'vit_B12_µg',\n",
       "       'niacin_mg', 'folate_µg', 'panthotenic_acid_mg', 'vit_c_mg', 'vit_d_µg',\n",
       "       'vit_e_activity_mg', 'potassium_mg', 'sodium_mg', 'chloride_mg',\n",
       "       'calcium_mg', 'magnesium_mg', 'phosphorus_mg', 'iron_mg', 'iodide_µg',\n",
       "       'zinc_mg'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns_before = dataset.columns\n",
    "dataset = dataset.dropna(axis=1, thresh=feature_threshold)\n",
    "columns_after = dataset.columns\n",
    "columns_after"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's explain what the above code does line by line. \n",
    "In the first code cell we declare a variable, `feature_threshold = math.ceil(0.8*dataset.shape[0])` to be the threshold according to which we are discarding columns. It gets the number of samples using the first entry of the `dataset.shape` attribute which returns a `tuple`. Then, we save the columns we had previously in order to see later what was removed. Afterwards, we apply the `dropna()` method of a pandas dataframe to drop all columns (determined by the `axis=1` argument), that have less than `feature_threshold` non-missing values. We save the columns aftre the drop as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['selenium_µg'], dtype='object')"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns_before.difference(columns_after)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `difference` method does simply set difference on the two lists specified. As you can see, `selenium_µg` is not present anymore in the columns list. The code cell below counts the number of columns. Now we have 40 columns, from 41 that we had before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset.columns)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing samples with a lot of missing values"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will do the same but row-wise. We will remove the samples that have more than  20% of the values missing. This means that we will keep the samples that have more than 80% of the features. With some quick math we find that: $$\\left\\lceil0.8*41 = 32.8 \\right\\rceil = 33$$ This means that we will keep the samples that have 33 or more features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       24\n",
       "1       30\n",
       "2        0\n",
       "3        0\n",
       "4        0\n",
       "        ..\n",
       "1087     0\n",
       "1088     0\n",
       "1089     0\n",
       "1090     0\n",
       "1091     0\n",
       "Length: 1092, dtype: int64"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nan_total_rows = dataset.isna().sum(axis=1)\n",
    "nan_total_rows"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code cell above finds the number of missing values per each sample. This time we sum row-wise by specifying the `axis=1` argument in the `sum()` method. [Figure 2](#boolean-mask-illustration) illustrates how the `isna()` and `sum()` methods work to calculate the number of `NaN`s per each sample and per each feature. Note that we just show an example of teh output for the first 3 samples and 10 columns. After creating the boolean masks ('tables' with 0s and 1s), it finds the sum per row or per column, based on the `axis` value we pass as argument to `sum()` and find the number of missing values."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "    <a id=\"boolean-mask-illustration\"></a>\n",
    "    <img src=\"images/part1_overview/rows_columns_nans.jpg\" alt=\"Rows and columns boolean mask\" width=\"90%\">\n",
    "    <center><figcaption><em>Fig 2: Compute number of missing values per row and column</em></figcaption></center>\n",
    "</center>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After finding the number of missing values per row, we will remove the rows that have more than 20% of the values missing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row_threshold = math.ceil(percentage_present*dataset.shape[1]) # 20% of values missing\n",
    "row_threshold"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We declare `row_threshold = math.ceil(0.8*dataset.shape[1])` to be the threshold according to which we are discarding rows. It gets the number of features using the second entry of the `dataset.shape` attribute which returns a `tuple`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1084, 41)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows_before = dataset.index\n",
    "dataset = dataset.dropna(axis=0, thresh=row_threshold)\n",
    "rows_after = dataset.index\n",
    "dataset.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From 1092 samples, now we have 1084."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([0, 1, 83, 84, 898, 899, 1022, 1057], dtype='int64')"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows_before.difference(rows_after)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again we apply the `difference()` method to find the positions of the samples that were dropped."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After removing the features and samples that had a lot of missing values, we have a dataset with 1084 samples and 41 features. Note that our dataset still has missing values and we will deal with them in the subsequent sections."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Outlier detection[work in progress...]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we continue our data quality analysis further we have to deal with the *outliers*. Outliers are points that differ from the majority of the samples in the dataset. Most of the machine learning models are sensitive to outliers since they affect the learning process. Thus it is importnant to deal with them. The easiest way is to completely remove them. However, in case where the dataset has only a few samples, this is not a very good approach. Thus instead we can instead keep the samples but modify the values within the range of the majority of the points. \n",
    "\n",
    "In our case, the dataset has many food categories, and each type of food will have different values for the features. Thus we have to take this characteristic into account when we determine what points will be outliers."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dealing with missing data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are several ways to deal with missing data. The easiest and most drastic one is to completely remove the samples (rows) that have missing data. We cannot apply this here because we would have to delete more than 70% of the dataset, meaning that we would have too few samples to do any meaningful analysis. Other approaches are possible for imputing the dataset, e.g. replace the missing values with some characteristic values of the features. For example, we can decide to substitute missing values in a column with the mean value for that feature. Likewise we can substitute them with the median or mode values. You can find more imputation techniques in the [sklearn documentation](https://scikit-learn.org/stable/modules/impute.html)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will impute the missing values with the mean of the features, but for each food category. Let us check which food categories do we have in our dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['fruits', 'nuts', 'cereals', 'sweets', 'other', 'dairy',\n",
       "       'non_alcoholic_beverages', 'vegetables', 'meat', 'herbs', 'sauce',\n",
       "       'alcoholic_beverages'], dtype=object)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['category'].unique()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above code cell does the following: it first selects all the rows of the `category` column of the dataset and then find all unique values in this column. There are 12 unique food categories in our dataset. In this case, we will find the mean value per food category and per feature, and aftewards, subsitute the missing values with the per category and per feature mean.\n",
    "Let us look at an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "starch_g     NaN\n",
       "category    meat\n",
       "Name: 221, dtype: object"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.loc[221, ['starch_g', 'category']]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This sample, that correspons to the `meat` category has a missing value for the feature `starch_g`.  Using the `loc` indexer we can select the row 221, and for that row we get only the dat that correspond to the specified columns, which in this case are inside the list `['starch_g', 'category']`. This value will be imputed with the mean of all the `starch_g` values for all food samples belonging to the `meat` category.\n",
    "To do so we will write a function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_missing_values(dataset:pd.DataFrame, category_col:str, feature_col_names:list)->pd.DataFrame:\n",
    "    modified_dataset = dataset.copy()\n",
    "    for feature in feature_col_names:\n",
    "            modified_dataset[feature] = modified_dataset.groupby(category_col)[feature].transform(lambda x: x.fillna(x.mean()))\n",
    "    return modified_dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function takes as arguments the dataset that we are imputing, the name of the column that specifies the category according to which we are grouping the food samples and the feature columns (all the numeric columns) were missing values may be present.\n",
    "\n",
    "First we begin by creating a copy of the dataset, in order not to modify the original one. Then, we iterate over all the numerical features of the dataset. For each feature, we group the dataset by the `category` column. This means that all samples belonging to the same category will be next to eachother (consecutive). This is achieved by `modified_dataset.groupby(category_col)[feature]`. Then for each of this groups we find the mean of all non-misisng values and at the same time we fill the missing values of that group with the mean. This is achieved by `transform(lambda x: x.fillna(x.mean()))`."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we use the function, we will define the columns that contain the numerical features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['energy_kcal', 'fat_g', 'fatty_acids_sat_g', 'fatty_acids_monounsat_g',\n",
       "       'fatty_acids_polyunsat_g', 'cholesterol_mg', 'carbohydrates_g',\n",
       "       'sugars_g', 'starch_g', 'fibres_g', 'protein_g', 'salt_g', 'alcohol_g',\n",
       "       'water_g', 'vit_A_activity_re_µg', 'vit_A_activity_rae_µg',\n",
       "       'retinol_µg', 'beta_carotene_activity_µg', 'beta_carotene_µg',\n",
       "       'vit_B1_mg', 'vit_B2_mg', 'vit_B6_mg', 'vit_B12_µg', 'niacin_mg',\n",
       "       'folate_µg', 'panthotenic_acid_mg', 'vit_c_mg', 'vit_d_µg',\n",
       "       'vit_e_activity_mg', 'potassium_mg', 'sodium_mg', 'chloride_mg',\n",
       "       'calcium_mg', 'magnesium_mg', 'phosphorus_mg', 'iron_mg', 'iodide_µg',\n",
       "       'zinc_mg'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = dataset.columns[3:] # select all columns from the fourth to the second from the end\n",
    "cols"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to call our function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = impute_missing_values(dataset, category_col='category', feature_col_names=cols)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to confirm that our function has imputed the `NaN` values, let's look at the example from above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "starch_g    0.265962\n",
       "category        meat\n",
       "Name: 221, dtype: object"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.loc[221, ['starch_g', 'category']]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it has the mean starch value for all meat products. In order to check that there are no `NaN` values anymore, we can check via the following piece of code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 41)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a boolean mask for NaN values\n",
    "nan_mask = dataset.isna().any(axis=1)\n",
    "\n",
    "# create a new DataFrame with samples containing NaN values\n",
    "df_with_nan_only = dataset[nan_mask]\n",
    "df_with_nan_only.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this method, we create a boolean mask for all indices of samples in the dataset that have at least one `NaN` value. Then in the fifth line we filter only the values that are  `True` in our boolean mask and find the shape of the filtered dataset. As we can see, this dataset has 0 rows, meaning that there are not anymore NaN values in our dataset."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='train-test-split'></a>Train-Test Split"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although in practice it happens after the real data preprocessing, sometimes it is considered to be part of the data pre-processing phase. As you can see from [Fig. 1](#ml-model), before the machine learning model is trained, the data is split in two parts: the **training data** and the **testing data**. Usually we use 70-80% of the whole dataset for training and the remaining 20-30% for testing. The reason that we do this, is to be able to quantify how well the model has learned the characteristics of the data. If the performance indicators will be great in the test part than we know that the model has learned the data well. If we see that performance indicators show poor results on the test set that this means that our model might have just \"learned by heart\" the training data."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to better understand this, let us make an analogy to your courses at ETH. When you go and sit in an exam, you rarely or never find exactly the same questions that you have seen during the exercise sessions or classes. Also, you never know in advance which questions will be asked in the exam. The reason for all this constraints is that the professors want to evaluate you based on what you have understood from the course. If you already knew the questions of the exam you can easily prepare them beforehand, try to memorize the answers even if you understand nothing and then you get a really good grade from the course. But what happens next is that when you start working outside the doors of the university, you will probably not be able to solve the tasks at hand because of lack of understanding of certain concepts and set of skills. \n",
    "\n",
    "This is exactly what we want to avoid when training machine learning models. In the machine learning jargon, we want to have models that generalize well. This means that they can properly solve tasks which they have not encountered during training. And they can do perfectly so, if the training was successful and they have gained insights on data. In our analogy from above, if the students understand the concepts and can put them to practice, then they can be flexible in their jobs and solve tasks that they might not have encountered during the studies. All this happens because they will have the necessary set of skills from their training (education) years. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below you can see how we can split in practice a dataset.\n",
    "For the splitting we will use the `train_test_split()` method from the `model_selection` module of the `sklearn` library, that we have imported above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, test_set = train_test_split(dataset, test_size=0.2, random_state=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We pass three arguments to the method. The first one is the dataset that will be split. The second one `test_size` determines the portion of the data that will be used for testing. Here we specify that `20%=0.2` will be used for testing, thus implicitly the remaining 80% for training. The method, depending on whether we pass the whole dataset or the features and the labels separately, will return 2 new dataframes in the first case (1x for the train set and 1x for the test set) or 4 new dataframes in the second case (1x for the train_features, 1x for the test features, 1x for the train labels and 1x for the test labels). The third argument, `random_state=0` makes sure that no matter how many times we execute the above code cell, it will produce the same split all the times. This means that the `train_set` and `test_set` will always have the same samples. If we omit that argument, then `train_set` and `test_set` will have different samples each time we execute the cell.\n",
    "\n",
    "In order to make sure that the split is correct let us check the sizes of the new dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of original dataset:  (1084, 41)\n",
      "Shape of train dataset:  (867, 41)\n",
      "Shape of test dataset:  (217, 41)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of original dataset: \", dataset.shape)\n",
    "print(\"Shape of train dataset: \", train_set.shape)\n",
    "print(\"Shape of test dataset: \", test_set.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This confirms our desired proportions for the split."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardization"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standardization is the process of transforming or rescaling the values of certain features so that they are comparable. This process is useful to the underlying steps of machine learning algorithms in finding the best model that can generalize the data. The formula for standardizing the values of a single feature column would be: $$ X^{(i)}_s = \\frac{X^{(i)}-\\mu}{\\sigma} ,$$ where $X^{(i)}_s$ is the standardized value for sample `i`, $X^{(i)}$ is the original value of the feature for sample `i`, $\\mu$ is the mean of all values of the feature (the whole column) and $\\sigma$ is the standard deviation of all the values of that feature. We can depict this graphically as follows:\n",
    "\n",
    "<center>\n",
    "    <a id=\"standardization-illustration\"></a>\n",
    "    <img src=\"images/part1_overview/standardization.jpg\" alt=\"Standardization\" width=\"75%\">\n",
    "    <center><figcaption><em>Fig 3: Standardization in practice</em></figcaption></center>\n",
    "</center>\n",
    "\n",
    "As you can see, we first find the mean, column-wise for a feature. Then we find the standard deviation and then we apply the above formula for each of the samples to transform that feature into a standardized one. We repeat this procedure for all the feature columns one by one. In addition, standardization makes the distributions of the features more uniform. **\n",
    "\n",
    "**NOTE**: If we are in a supervised learning task, then we apply the scaling to all features but not to the label/target column. We avoid this because it might change the interpretation of the target variable. While in the case of unsupervised learning, the standardization may be applied to all columns since there is no target column."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using this method, the mean of each corresponding feature is subtracted from the values and each of them is scaled to unit variance. Moreover, by using standardization the learning models will not be affected a lot by outliers and the learning process will be smoother. This happens due to some underlying properties of the standard normal distribution that are out of the scope of this notebook."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can either code the procedure by ourselves or we can use ready-made code from the `sklearn` module. Here you will see an example of how to do standardization using `StandardScaler` from `sklearn`. We will continue using the dataset from the previous section. \n",
    "Again, we will start by importing the necessary modules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "standard_scaler = StandardScaler()\n",
    "train_set_numerical_st = standard_scaler.fit_transform(train_set.iloc[: , 3:])\n",
    "test_set_numerical_st = standard_scaler.transform(test_set.iloc[: , 3:])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After creating the `standard_scaler` object we use its method `fit_transform` **only in the numerical part of the `train_set`**. Then, **for test set, we use the `transform` method.** This is done to avoid any information leakage from the train to the test set, since it will be used to evaluate the machine learning models. In addition, since we assume that both the train and the test sets come from the same distribution, then there should be no difference between their means and standard deviations.  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both these methods return *numpy arrays*. We will convert the standardized train and test sets into *pandas dataframes* so that we can save them in files and use in the next tutorials. To do so we run the below code cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select only the names of the columns that have been standardized\n",
    "numerical_column_names = train_set.iloc[: , 3:].columns\n",
    "\n",
    "# create dataframes from the arrays by passing the arrays and feature names as arguments \n",
    "train_set_st_df = pd.DataFrame(train_set_numerical_st, columns=numerical_column_names)\n",
    "test_set_st_df = pd.DataFrame(test_set_numerical_st, columns=numerical_column_names)\n",
    "\n",
    "# reset indices so that both original and standardized dataframes have the same index\n",
    "train_set_st_df.index = train_set.index\n",
    "test_set_st_df.index = test_set.index\n",
    "\n",
    "# concatenate the standardized numerical dataframe with the non numerical part of the original\n",
    "train_set_st = pd.concat([train_set.iloc[:, :3], train_set_st_df], axis=1, ignore_index=False)\n",
    "test_set_st = pd.concat([test_set.iloc[:, :3], test_set_st_df], axis=1, ignore_index=False)\n",
    "\n",
    "# save the dataframes to two files - so that we can use them later\n",
    "train_set_st_df.to_csv('data/swiss_food_composition_database_train_standardized.csv', index=False)\n",
    "test_set_st_df.to_csv('data/swiss_food_composition_database_test_standardized.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The comments in the code explain what each line does."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us have a look how standardization changes the distribution of the features. For  this, we will plot the histogram of the values for the `fruit` category and the `energy_kcal` feature. Note that this step is not necessarily part of the machine learning pipeline we have seen so far. This is not needed for the model itself, but we will use it to give us an idea of what happens after standardization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_fruit_energy = train_set[train_set['category']=='fruits'].iloc[:, 3]\n",
    "standardized_fruit_energy = train_set_st[train_set_st['category']=='fruits'].iloc[:, 3]\n",
    "energy_fruits_df = pd.DataFrame({'Original': original_fruit_energy, 'Standardized': standardized_fruit_energy})\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We begin by creating a new dataframe that will contain two columns, one with the original energy values for all fruits and one with the corresponding standardized values. After having the dataframe ready, we plot each columns histogram:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(10, 4))\n",
    "\n",
    "# this is the command for the actual plot\n",
    "sns.histplot(data=energy_fruits_df, x='Original', ax=axes[0], color='blue', alpha=0.7, binwidth=80)\n",
    "axes[0].set_xlabel('Original') # define the label for the x-axis of the left subplot\n",
    "axes[0].set_ylabel('Frequency') # define the label for the y-axis of the left subplot\n",
    "sns.histplot(data=energy_fruits_df, x='Standardized', ax=axes[1], color='red', alpha=0.7, binwidth=80)\n",
    "axes[1].set_xlabel('Standardized') # define the label for the x-axis of the right subplot\n",
    "axes[1].set_ylabel('Frequency') # define the label for the y-axis of the right subplot\n",
    "\n",
    "plt.suptitle('energy_kcal distribution')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By analyzing these two plots, we can see that the data after standardization is more uniform. On the right plot, we see that values are spread non-uniformely from 0 up around 750, while on the right subplot, all values are in a single bin (from 0-80). This means that they are on the same scale, which was the goal of standardization."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this, we conclude the `Overview` tutorial. Next on, we will explore supervised and unsupervised learning."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**References:**\n",
    " - \"Machine Learning with Pytorch nd Scikit-Learn\" - Sebastian Raschka, Yuxi Liu, Vahid Mirjalili, Dmytro Dzhulgakov.\n",
    " - Raw data from https://naehrwertdaten.ch/en/downloads/."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
