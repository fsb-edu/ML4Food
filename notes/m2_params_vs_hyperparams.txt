
In machine learning, parameters and hyperparameters play different roles. The **parameters** are values that **the machine learning model learns from the data**. At the end of the learning process, the data will be described by a mathematical equation. The main goal of the learning process is to find the parameters of this mathematical equation that would best describe the data. For example, suppose that you have some points scattered in a 2D coordinate system. Your aim is to find the line with an equation of the form: $$y = ax + b$$. 

In this case, `a` and `b` would be the parameters that the model would learn from the points so that the line would represent them in the best possible way.

On the other hand, **hyperparameters control the learning process itself and how the parameters will be computed**. Hyperparameters are set by the data scientists/analysts and they are not learned by the model. You can think of them as **settings or configurations to tune the learning process**. Usually people use intuition, trial-and-error, and other, more sophisticated techniques like cross-validation to pick the right hyperparameters that would make the learning process faster and produce more accurate results. Going to the line example, the hyperparameters will determine **how complex** the equation of the line that will describe the points will be. 

All in all, **parameters determine the model output, while hyperparameters determine the way how the parameters would be learned**. You can read more about the distinction between parameters and hyperparameters [in this blog post](https://towardsdatascience.com/parameters-and-hyperparameters-aa609601a9ac).


ðŸ’¡ **CHECKPOINT:**
- How do parameters differ from hyperparameters? What role does each of them play in the learning process?
- What is tuned by the data analyst and what is learned by the model?
- Determine which of the following are parameters and which are hyperparameters in the following scenario: *We have a dataset that contains 1000 points, each of them having a single feature. The function that will approximate these points will have the form $y=ax^2+bx+c$. We do not want the model to overfit the data, so we set a regularization parameter Î»=0.1, to be used during the training process. Since we do not want to wait long, we also determine the number of steps that the loss function will be computed and the weights updated, n=100.* Given this scenario, determine whether a, b, c, Î» and n are parameters or hyperparameters.